---
output:
  pdf_document: default
  html_document: default
---
Stat/QSci 403         Final Project   
=======================================================
Names go here
Cameron Sims
-------------------------------------------------------
``` {r pre-proc, echo=FALSE}
# Data Processing
data <- read.csv("rideshare_kaggle.csv")
dat <- data[, c("source","product_id", "destination", "cab_type","price", "distance",
               "temperature", "apparentTemperature", "short_summary",
               "humidity", "windSpeed", "windGust", "visibility", 
               "temperatureHigh", "temperatureLow", "pressure", "windBearing",
               "cloudCover", "uvIndex", "ozone", "moonPhase")]

# without non-temp data
dat <- data[, c("source","distance","price", "product_id", "temperature", "apparentTemperature", 
                "short_summary", "humidity", "windSpeed", "windGust", "visibility",
                "temperatureHigh", "temperatureLow", "pressure", "windBearing",
                "cloudCover", "uvIndex", "ozone", "moonPhase")]

# remove rows with NA
dat <- dat[complete.cases(dat[,"price"]),] # remove with NA price

lyft <- dat[which(dat[,"product_id"] == "lyft"),]                 #51235
lyft_line <- dat[which(dat[,"product_id"] == "lyft_line"),]       #51233
lyft_lux <- dat[which(dat[,"product_id"] == "lyft_lux"),]         #51235
lyft_luxsuv <- dat[which(dat[,"product_id"] == "lyft_luxsuv"),]   #51235
lyft_plus <- dat[which(dat[,"product_id"] == "lyft_plus"),]       #51235
lyft_premier <- dat[which(dat[,"product_id"] == "lyft_premier"),] #51235

# remove product_id now that we have split
lyft$product_id <- NULL
lyft_line$product_id <- NULL
lyft_lux$product_id <- NULL
lyft_luxsuv$product_id <- NULL
lyft_plus$product_id <- NULL
lyft_premier$product_id <- NULL

##### STILL NEED TO PURGE REMAINING IF GONNA USE
lyft_premier <- lyft_premier[which(lyft_premier[,"source"] == "Back Bay"),]
lyft_premier$source <- NULL
lyft_premier <- lyft_premier[which(lyft_premier[,"distance"] <3),]
lyft_premier <- lyft_premier[which(lyft_premier[,"distance"] >2.5),]
lyft_premier$distance <- NULL
# lyft_premier$price <- NULL

# Code to limit hours, didn't really make a difference
# lyft_premier <- lyft_premier[which(lyft_premier[,"hour"] == 11 | lyft_premier[,"hour"] == 12 | lyft_premier[,"hour"] == 13),]
```

# Introduction:
In the society that develops as amazingly as ours, a more convenient way of transportation has become crucial for us. 
The appearance of ride-share apps like Uber and Lyft seems to solve this problem very well; however, the complicated pricing 
rules behind these softwares have been bothering users. Users may notice that the similar trips with same fare type can end up 
with huge price differences, even they were only told that the apps are mostly charge by distance. In order to better help 
users understand the factors that affect the price of every trip, our group decided to study the impact of environmental 
factors on ride-share pricing. 

Our initial ideas and logic are very simple and straightforward. With worse weather conditions, people are less likely to walk 
or use public transportations, in this way, there is higher demand of ride-share, and the will be higher. While using the app, 
we can easily notice that there is always a pop-up surge multiplier notice when the weather condition is bad, or during late 
night or rush hours.

The data set that we analyzed was based on 693071 trips from variety products of Uber and Lyft in Boston, which is a city with 
unstable weather conditions. There are basic Information collected form the ride-share company of each trip, such like price, 
distance, surge multiplier, and product type. Also, there are corresponding environmental factors - temperature, humidity, 
wind speed, wind gust, visibility, pressure, cloud cover, uv index, and moon phase. In order to make our analysis more 
reference value, we eliminate useless data and refine our research to only one type of product - Lyft Premier trips start from 
Back Bay with distance between 2.5 and 3 miles. 

The public literatures that can be referred are very limited. We can only find one paper from Oklahoma State University 
analyzed the relationship between weather type and number of ride-shares in Boston. In their paper, the key finding is that 
transitions in weather play a crucial role in the number of rides called. With the lack of existing research about this topic, 
our group decided to test few models, then discuss wether those models are fit for our topic. We also wanted to discuss if 
some models can help us make perditions of future trip fares with particular weather conditions.

# Methods:
Need to talk about what we are doing
-> data we are using
-> weather data we are using
# Results:
We will now go into a discussion of the various models considered and their outcomes.

## Linear Models:
Our first attempt at modeling the relationship between various weather predictors and rideshare price was a linear model. We first fit using all the available predictors. 

```{r linear-all, echo=FALSE}
library(leaps)
library(knitr)
cur_data <- lyft_premier
cur_data$short_summary <- NULL

cur_data.lm <- lm(price~., data=cur_data)

X = model.matrix(cur_data.lm)

kable(summary(cur_data.lm)$coefficients,
      caption = "Table of coefficients for linear model with all predictors",
      digits = 1)
```

This model does not explain the variablity we see in price. It has an r-squared value of `r sprintf("%.3f",summary(cur_data.lm)$r.squared)`. In other words, less than 5% of the variablity we see in price is explained by our model.

As we can see from Table (1), the only significant coefficient is moonPhase. However, this is likely due to the complexity of the model, as fitting price with only moonPhase lead to a non-significant coefficient. Furthermore, running stepwise selection to find the best subset of predictors also supports this conclusion.

``` {r lm-all-regfit, echo=FALSE,fig.height=3, fig.cap="\\label{fig:lm-all-regfit}Plots of Mallow's Cp and RSS for various model sizes"}
fit <- regsubsets(X, cur_data$price, intercept=FALSE, nvmax=14, method="forward")

par(mfrow=c(1,2))
x <- seq(1,length(fit$rss),1)
plot(x, fit$rss,type = "l", xlab = "size", ylab = "RSS", main="size vs RSS")

plot(x, summary(fit)$Cp, type="l", xlab="size", ylab="Cp", main="size vs Cp")
```

FromFigure \ref{fig:lm-all-regfit}, we see that RSS decreases with increased model complexity, as expected. However, we do not see the expected quadratic shape for Mallow's Cp index. Rather we see a positive linear increase, meaning that a model of size 1 (only intercept) is optimal. This means that we are best off simply taking an average of our response (price).

Moving on, our next step was to limit our predictors. We decided to choose the following 5: windSpeed, ApparentTemperature, uvIndex, pressure, and humidity. Here is our reasoning for selecting these. We would expect that with high wind speeds, indviduals are less likely to walk and will therefore order more lyfts. Similarly, a high uvIndex is unhealthy and so we would expect a linear relationship. A high humidity would make walks less bearable and therefore we would expect a higher demand of rideshares. Low pressure is associated with higher likelihood of rain and under worse conditions we would expect more rides to be hailed. Lastly, at extreme apparent temperatures, we would expect individuals to be less likely to walk - a quadratic relationship between temperature and demand.

``` {r interaction-plots, echo=FALSE,fig.height=4,fig.width=10, fig.cap="\\label{fig:interaction-plots}Scatterplots of every pair of predictors"}
pairs(lyft_premier[,c("windSpeed","apparentTemperature","uvIndex","pressure","humidity")], cex.labels=1.25, bg='orange', cex=.3)
```

FromFigure \ref{fig:interaction-plots} we can see a positive correlation between WindSpeed and apparentTemperature, as well as between humidity and apparentTemperature. We also see a negative correlation between pressure and WindSpeed. To account for this within our model, we added interaction terms between these predictors. Further, to account for assumption of apparentTemperature being quadratic, we added ploynomial terms for the temperature predictor.

```{r linear-small, echo=FALSE}
library(leaps)
library(knitr)
cur_data <- lyft_premier
cur_data$short_summary <- NULL

cur_data.lm <- lm(price~windSpeed+poly(apparentTemperature,2)+uvIndex+pressure+humidity
                  +windSpeed:apparentTemperature
                  +humidity:apparentTemperature
                  +pressure:windSpeed, data=cur_data)

X = model.matrix(cur_data.lm)

kable(summary(cur_data.lm)$coefficients,
      caption = "Table of coefficients for linear model with limited predictors",
      digits = 1)
```

We see that the increased complexity from using all the predictors did a better job of explaining the variability in price as using only a subset of the variables with interaction terms actually led to a decrease of r-squared to `r sprintf("%.3f",summary(cur_data.lm)$r.squared)`.

As we can see from Table (2), there are no significant coefficients under the significance level $\alpha = 0.05$. Running stepwise selection to find the best subset of predictors gives a similar outcome to using all the predictors.

``` {r lm-small-regfit, echo=FALSE,fig.height=3, fig.cap="\\label{fig:lm-small-regfit}Plots of Mallow's Cp and RSS for various model sizes"}
fit <- regsubsets(X, cur_data$price, intercept=FALSE, nvmax=14, method="forward")

par(mfrow=c(1,2))
x <- seq(1,length(fit$rss),1)
plot(x, fit$rss,type = "l", xlab = "size", ylab = "RSS", main="size vs RSS")

plot(x, summary(fit)$Cp, type="l", xlab="size", ylab="Cp", main="size vs Cp")
```

FromFigure \ref{fig:lm-all-regfit}, we see that a model of size 1 (only intercept) is optimal. This means that we are best off simply taking an average of our response (price). 

We see that through simple linear and non-linear models, we were unable to account for the variability in price for rideshares.

## Threshold Analysis:

Our next analysis was on the precentage of rides we see above a certian threshold. As we can see fromFigure \ref{fig:emp-boot-thres} there is a steep dropoff at $25 so our intuition is this the percentage of rides above this threshold can be an indicator of demand.

``` {r emp-boot-thres,echo=FALSE,fig.height=3, fig.cap="\\label{fig:emp-boot-thres}Plot of price distribution (left) Plot of boostrap distribution (Right)"}
par(mfrow=c(1,2))

# just straight up fitting exponential using mle for lambda
lambda.hat <- 1/mean(lyft_premier[,"price"]-15)

x <-0:35
hist(lyft_premier[,"price"]-15, col="tan", probability=T, xlab="Price - 15", main="Distribution of Price")
lines(x,dexp(x,rate=lambda.hat), col=2)
legend("topright", legend="mle exp", col=2, lwd=2)

cur_data <- lyft_premier

thres <- 25

B <- 10000
above.orig <- length(which(cur_data$price>thres))/nrow(cur_data)

# holder of boostrap sample percentage
above.BT <- rep(NA, B)

for (i in 1:B) {
  samp <- sample(nrow(cur_data), nrow(cur_data), replace=T)
  BT <- cur_data[samp,]
  above.BT[i] <- length(which(BT$price>thres))/nrow(BT)
}

hist(above.BT, col="tan", breaks=10,main="Hist of % above threshold", xlab="%")
abline(v=above.orig, col="red", lwd=3)
legend("topright", legend="original sample %", col="red", lwd=3)

basic <- quantile(above.BT, c(0.05,0.95)) # quantile method
```

\ref{fig:emp-boot-thres} (Left) is a distribution of the rideshare prices we see with an exponential distribution with the maximum likelihood estimate for $\lambda$. As we can see the fit is not quite exponential.

Next, we performed a bootstrap analysis of the percentage of rides we see above our threshold ($25) to estimate our true population value. From,Figure \ref{fig:emp-boot-thres} (Right) we can see that bootstrap samples had percentages approximately normally distributed around our sample value. The 90% confidence interval for the population value is :[`r sprintf("%.3f",basic[1])`, `r sprintf("%.3f",basic[2])`]. Hence, we are 90% confident that the true population percentage is between `r sprintf("%.3f",basic[1])` and `r sprintf("%.3f",basic[2])`. 

## Logistic Models

Following our threshold analysis, we performed logistic regression on the relationship between moonPhase and price, as well as, pressure and price. We appended a column to our data labeled **above** which took a value of 1 if the price for that specific observation was above the threshold ($25).

``` {r log,echo=FALSE,fig.height=3, fig.cap="\\label{fig:log}MoonPhase logistic (left) Pressure logistic (Right)"}
cur_data <- lyft_premier
thres <- 25              # desired threshold for price

# add indicator variable
cur_data$above <- as.numeric(cur_data$price > thres)

# fit basic logistic to data
fit_logistic_m = glm(above ~ moonPhase, data=cur_data, 
                   family = "binomial")

aic.m <- summary(fit_logistic_m)$aic

# 90% CI
xs = data.frame(moonPhase = seq(from=0.09,to=0.93, by=.001))
pred = predict(fit_logistic_m, type="response", newdata=xs, se=T)

p.m = pred$fit
p_U.m = pred$fit+qnorm(0.95)*pred$se.fit
p_L.m = pred$fit-qnorm(0.95)*pred$se.fit

par(mfrow=c(1,2))

plot(xs$moonPhase, p.m, type="l", lwd=6, col="blue", xlab="moonPhase", ylim=c(0,1), 
     ylab="Probability of having price above 25")
points(cur_data$moonPhase, cur_data$above, col=2)
lines(xs$moonPhase, p_U.m, col="dodgerblue", lwd=3,
      lty=2)
lines(xs$moonPhase, p_L.m, col="dodgerblue", lwd=3,
      lty=2)

# pressure fit
fit_logistic_p = glm(above ~ pressure, data=cur_data, 
                   family = "binomial")

aic.p <- summary(fit_logistic_p)$aic

# 90% CI
xs = data.frame(pressure = seq(from=988,to=1035, by=.5))
pred = predict(fit_logistic_p, type="response", newdata=xs, se=T)

p.p = pred$fit
p_U.p = pred$fit+qnorm(0.95)*pred$se.fit
p_L.p = pred$fit-qnorm(0.95)*pred$se.fit

plot(xs$pressure, p.p, type="l", lwd=6, col="blue", xlab="pressure",ylim=c(0,1),
     ylab="Probability of having price above 25")
points(cur_data$pressure, cur_data$above, col=2)
lines(xs$pressure, p_U.p, col="dodgerblue", lwd=3,
      lty=2)
lines(xs$pressure, p_L.p, col="dodgerblue", lwd=3,
      lty=2)
```

As we can see from the plots, these fits are not very successful. We see a higher probability of seeing increased variability for a higher moonPhase (closer to full moon) and for lower pressure. The AIC scores for moonPhase is `r sprintf("%.1f",aic.m)` and pressure is `r sprintf("%.1f",aic.p)`. Both are extremely high meaning we likely cannot draw any inferences from the fit. We see a similar trend regardless of what predictor we use.

## Permutation test

Since we were having trouble finding significant predictors for price, we decided to test if the mean prices between the different weather types were significant. To do this, we performed a permutation test between the mean prices of each weather type, which included a lot of combinations. In doing so, we were able to determine which differences between weather types were significant.

```{r permutations}
perm_data <- data.frame(xx=character(), yy=character(), perm_result=double(),
                        stringsAsFactors = F)

# Function to perform permutation test between means
perm_test <- function(xx, yy){
  # Calculate means and difference
  xx_mean <- mean(xx)
  yy_mean <- mean(yy)
  diff_mean <- abs(xx_mean - yy_mean)
  
  # Calculate lengths and combined length
  n_x <- length(xx)
  n_y <- length(yy)
  n <- n_x + n_y
  
  # Combine data
  data_pull <- c(xx, yy)
  
  # Perform permutation test
  n_per <- 1000
  diff_mean_per <- rep(NA, n_per)
  set.seed(160) # For reproducible results
  for (i_per in 1:n_per){
    w_per <- sample(n, n, replace=T)
    data_per <- data_pull[w_per]
    datax_new <- data_per[1:n_x]
    datay_new <- data_per[(n_x+1):n]
    diff_new <- abs(mean(datax_new)-mean(datay_new))
    diff_mean_per[i_per] <- diff_new
  }
  
  # Return p-value
  return((length(which(diff_mean_per>diff_mean))+1)/n_per)
}

# Permutation Tests for means between prices depending on weather
for (i in 1:8){
  
  # Get and set name for xx
  xx <- lyft_premier[lyft_premier$short_summary==unique(lyft_premier$short_summary)[i],]
  
  for (j in i:8) {
    
    # Get and set name for yy
    yy <- lyft_premier[lyft_premier$short_summary==unique(lyft_premier$short_summary)[j+1],]
    
    # Get and set permutation result
    perm_result <- perm_test(xx$price, yy$price)
    
    # Add data to perm_data
    new_df <- data.frame(xx=as.character(xx$short_summary[1]),
                         yy=as.character(yy$short_summary[1]),
                         perm_result=perm_result)
    perm_data <- rbind(perm_data, new_df)
  }
}

# Reorder perm_data based on p-vals
perm_data <- perm_data[order(perm_data$perm_result),]
```

## Conclusion. 

The permutation tests managed to reveal significant differences between mean prices for different weathers, such as "Overcast" and "Light Rain". Overall, there were 6 differences with p-values less than 10%, 2 of which were below 5%. Examining the table, it is interesting to see what weathers had significantly different mean prices and how significant these differences were. For example, "Overcast" and "Light Rain" are somewhat similar weathers, yet they had the most significant difference. These permutation tests gave us an idea on how to proceed with future analyses, as we had discovered a few pieces of useful information.

``` {r price,echo=FALSE,fig.height=3, fig.width=6, fig.cap="\\label{fig:price}Scatterplot of apparentTemperature and price"}
plot(lyft_premier$apparentTemperature, lyft_premier$price, xlab="apparentTemperature", ylab="price", main="temp vs price")
abline(h=mean(lyft_premier$price), col=2)
legend("top", legend="mean price", col=2,lwd=1, cex=.7)
```

However, most of our attempts to fit a relationship on the data were rather unsuccessful. This most likely can be attributed to our distribution of prices.Figure \ref{fig:price} is a plot of price and apparentTemperature. As we can see, price is not continious. Rather, we see horizontal bands develop. This makes us believe that Lyft's pricing algorithm is a constant multiplied by a surge parameter which is altered based on Lyft's estimation of the demand (likely intervals) and for this reason we see these horizontal lines develop. However, this could also possibly be attributed to how the data was collected. Rideshare companies do not make their pricing information public. This is to prevent price manipulation by the drivers. Because of this, the data was likely mined and perhaps the prices were estimated or rounded. Another possible explanantion is that this dataset had rides limited to about 4 miles. Perhaps if we had access to a dataset with rides of larger distances, we would see more varaition in the pricing and our models would have more success. 

  While unsuccessful, these horizontal bands gave us the intuiton to do perform the threshold and logistic analysis as we see increased variability for prices above $25. For further analysis, we would like to do a similar analysis on rides of longer length. We believe that our methods would likely see more success. In addition, our paper was focused on Lyft rides. Similar analysis to what was seen in this paper should be performed on an Uber dataset to see if there are significant differences between the two companies.

## Index:
Probably wont need this

## References:



Here is how I am preprocessing the data:

Some things to notice:

- all datapoints are from november-december 2018 in Boston (month param probably kinda useless)
- product_id and name refer to if it is a luxury cab, a plus ... 
- distance is between 0-4 mainly (some extremes to max of about 8)
- almost all datapoints have surge multiplier on??
- short_summary has 9 levels (might be good enough -> ignore long_summary)
- precip intensity seems to have a very small range and too little cases where it isnt 0
- precip Probability could be used in some sort of logistic prediction?
- mainly avoided timestamps
- icon seems to be very similar to the summaries
- not really sure what dewPoint is but ill include it for now
- uvIndex seems like a nice catagorical variable for us to use -> only 3 levels 
- visibility vs visibility.1? no clue how they differ
- I think the moon phase variable is sweet
- not sure how temperatureMin and temperatureMax differ from temperatureHigh and temperatureLow
- there are also apparent temperature max and lows but i left those out for now.

Here are the temp data
  - Price -> real number
  - temperature -> real number
  - short_summary -> catagorical (9 lvls)
  - humidity -> real number
  - windSpeed -> real number
  - windGust -> real number
  - visibility -> real number
  - temperatureHigh -> real number
  - temperatureLow -> real number
  - pressure -> real number
  - windBearing -> integer
  - cloudCover -> real number
  - uvIndex -> integer
  - ozone -> real number
  - moonPhase -> real number
  - product_id -> factor (13 levels but only 6 usable)

The only data with NA was price with (55095). I removed these rows completely.




```{r, fig.height=6}
library(corrplot)
cor_map_data <- lyft_premier
cor_map_data$short_summary <- NULL

cor_matrix <- cor(cor_map_data)
corrplot(cor_matrix)
```

Here are some things we are planning on doing:
- lm on all the variables (some of these are catagorical so we will need to create dummy variables)
- forward/backward stepwise selction on the variables
- KDE using cross val to estimate bandwidth
- maybe consider doing some sort of regression tree (easy to interpret -> see which vars are most important)
  - if we go down this road we could do boosting trees which use boostrap
  
```{r stepwise}
library(leaps)
# Create test/train sets
train=sample(c(TRUE,FALSE), nrow(lyft_premier),rep=TRUE)
test=(!train)

# Apply regsubsets to training set
regfit.best=regsubsets(price~.,data=lyft_premier[train,],nvmax=19)

# Make model matrix from test data
test.mat=model.matrix(price~.,data=lyft_premier[test,])

# Compute test MSE for models of different sizes
val.errors=rep(NA,19)
for(i in 1:19){
  coefi=coef(regfit.best,id=i)
  pred=test.mat[,names(coefi)]%*%coefi
  val.errors[i]=mean((lyft_premier$price[test]-pred)^2)
}

# Plot of data
plot(seq(1,19), val.errors, main="Test MSE vs. Number of Predictors",
     xlab="Number of Predictors", ylab="Test MSE", type='l')
points(which.min(val.errors), min(val.errors), col='red')


# Best model with optimal number of variables
regfit.best=regsubsets(price~.,data=lyft_premier,nvmax=19)
coef(regfit.best,which.min(val.errors))
```




```{r lasso regression & prediction}
library(tidyverse)
library(data.table)
df<-fread('rideshare_kaggle.csv')
# remove NAs
df<-na.omit(df)
# retain the observation with  "Back Bay", 'lyft_premier' and distance distributed from 2.5 to 3
df<-df%>%filter(source=="Back Bay" & product_id=='lyft_premier' & distance>2.5 & distance<3)
df<-data.frame(df)
# seprate the data into train set (70%) and test set (30%)
train.index<-sample(1:nrow(df),0.7*nrow(df))
train<-df[train.index,]
test<-df[-train.index,]
# lasso regression model
library(glmnet)
x<-as.matrix(train[,c('distance','temperature','surge_multiplier','humidity',
            'windSpeed','windGust','dewPoint','cloudCover','windBearing')])
x.test<-as.matrix(test[,c('distance','temperature','surge_multiplier','humidity',
                           'windSpeed','windGust','dewPoint','cloudCover','windBearing')])
y<-train$price
y.test<-test$price
# Cross Validation to tune the best lambda
cv.lasso<-cv.glmnet(x=x,y=y)
plot(cv.lasso)
fit.lasso<-glmnet(x=x,y=y,lambda=cv.lasso$lambda.min)
# prediction
pred<-predict(fit.lasso,x.test)
plot(pred,y.test)
abline(lm(y.test~pred),col=2,lty=2)
```
